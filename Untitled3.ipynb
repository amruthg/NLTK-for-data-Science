{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLwH6bZo9nLM"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#======================================================================\n",
        "#  Exercise:  1.Understanding Text Classification\n",
        "#             2.Feature Extraction from Text\n",
        "#             3.Building a Text Classifier using NLTK\n",
        "#             4.Evaluating the Text Classifier\n",
        "#Author: Amruth Gadepalli\n",
        "#IIIT Banglore.2nd Year\n",
        "#\n",
        "#Date : 9th January 2024\n",
        "#======================================================================\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text classification is a process of classifing test into various classes. for example: we can classify it in temrs of positive, negative and neutral. this classification is done by providing a lot of data to the model."
      ],
      "metadata": {
        "id": "JLu3n6xB-mHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1:"
      ],
      "metadata": {
        "id": "Pcz-hUvp-_rX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#before we clasify the texts, we need to convert the text to numbers which the ML algorithms can understand.\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#sample data\n",
        "documents = [\n",
        "    \"it is raining today.\",\n",
        "    \"Aritificial Intelligence is now a reality.\",\n",
        "    \"sentiment analysis helps in understanding the users feelings.\"\n",
        "]\n",
        "\n",
        "#create a CountVectorizer instance\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "#fit and transform the data into a feature matrix\n",
        "feature_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"Feature Matrix:\")\n",
        "print(feature_matrix.toarray())\n",
        "print(\"vocabulary:\",vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0UlrkTe--Rk",
        "outputId": "59de4b06-a609-4131-f421-c089048182dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Matrix:\n",
            "[[0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0]\n",
            " [1 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1]]\n",
            "vocabulary: ['analysis' 'aritificial' 'feelings' 'helps' 'in' 'intelligence' 'is' 'it'\n",
            " 'now' 'raining' 'reality' 'sentiment' 'the' 'today' 'understanding'\n",
            " 'users']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2:"
      ],
      "metadata": {
        "id": "vvHc3TRpA710"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhcBy-xrDONh",
        "outputId": "67cb8d17-bd23-4b7f-fc88-60e4c3920e80"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.classify.util import accuracy as nltk_accuracy\n",
        "\n",
        "#prepare data for sentiment analysis\n",
        "positive_reviews=[(movie_reviews.words(fileid),'positive') for fileid in movie_reviews.fileids('pos')]\n",
        "negative_reviews=[(movie_reviews.words(fileid),'negative') for fileid in movie_reviews.fileids('neg')]\n",
        "reviews = positive_reviews + negative_reviews\n",
        "\n",
        "#create feature sets using BoW representation\n",
        "def extraction_features(words):\n",
        "  return dict([(word, True) for word in words])\n",
        "\n",
        "feature_sets = [(extraction_features(words),sentiment) for (words,sentiment) in reviews]\n",
        "\n",
        "#split the dataset into training and testing sets\n",
        "train_set = feature_sets[:800]\n",
        "test_set = feature_sets[800:]\n",
        "\n",
        "#build the naive bayes classifier\n",
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "#test the classifier on the testing set\n",
        "accuracy = nltk_accuracy(classifier, test_set)\n",
        "\n",
        "print(\"Accuracy:\" , accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmiuACSmBBPI",
        "outputId": "3f2a342a-eacc-4abb-a276-8df7735fdd78"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.16666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "exercise 3:\n"
      ],
      "metadata": {
        "id": "BiAJimnCAMEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics import ConfusionMatrix\n",
        "\n",
        "# prepare the true labels and predicted labels for the testing set\n",
        "\n",
        "true_labels = [sentiment for(_, sentiment) in test_set]\n",
        "predicted_labels = [classifier.classify(features) for (features, _) in test_set]\n",
        "\n",
        "#compute confusion matrix\n",
        "cm = ConfusionMatrix(true_labels, predicted_labels)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "#compute precision recall, and F1-score\n",
        "precision = cm['positive','positive'] / cm['positive','positive']+cm['negative','positive']\n",
        "recall = cm['positive','positive'] / cm['positive','positive']+cm['positive','negative']\n",
        "f1_score = 2*(precision * recall)/(precision +recall)\n",
        "\n",
        "print(\"precision:\",precision)\n",
        "print(\"recall:\",recall)\n",
        "print(\"F1-score:\",f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SADy8rO3ANj9",
        "outputId": "5078c747-c76b-40fb-9dde-3a30690f8a4a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "         |    n    p |\n",
            "         |    e    o |\n",
            "         |    g    s |\n",
            "         |    a    i |\n",
            "         |    t    t |\n",
            "         |    i    i |\n",
            "         |    v    v |\n",
            "         |    e    e |\n",
            "---------+-----------+\n",
            "negative |   <.>1000 |\n",
            "positive |    . <200>|\n",
            "---------+-----------+\n",
            "(row = reference; col = test)\n",
            "\n",
            "precision: 1001.0\n",
            "recall: 1.0\n",
            "F1-score: 1.998003992015968\n"
          ]
        }
      ]
    }
  ]
}