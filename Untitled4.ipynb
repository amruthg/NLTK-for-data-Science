{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-aOXCrSDiss"
      },
      "outputs": [],
      "source": [
        "#======================================================================\n",
        "#  Exercise:  1.Introduction to Sentiment Analysis\n",
        "#             2.Sentiment Lexicons and Datasets\n",
        "#             3.Building a Sentiment analyser with NLTK\n",
        "#Author: Amruth Gadepalli\n",
        "#IIIT Banglore.2nd Year\n",
        "#\n",
        "#Date : 10th January 2024\n",
        "#======================================================================"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment analysis helps in idenitfying the sentiment in a text.\n",
        "ex: positive,negative and neutral"
      ],
      "metadata": {
        "id": "5oLcfhDaDkHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download the VADER lexicon\n",
        "nltk.download('vader_lexicon')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euNJ5uf3F55J",
        "outputId": "5c4ffc19-37f6-4ba4-a4b8-dd2ae1b90d75"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1:"
      ],
      "metadata": {
        "id": "Na9iAIzPnLC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using vader sentiment analyser from NLTK\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "#sample text to be analysed\n",
        "text = \"wow! this is such an amazing product!\"\n",
        "\n",
        "#create an instance of SentimentIntensityAnalyser\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "#get the sentiment score of a text\n",
        "sentiment_score = sia.polarity_scores(text)\n",
        "\n",
        "print(\"sentiment_score\",sentiment_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4Ptw2eKDu8K",
        "outputId": "9eebbd49-b87f-47c6-87bc-26d68e856c69"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment_score {'neg': 0.0, 'neu': 0.379, 'pos': 0.621, 'compound': 0.8475}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-srH7K_fZ-G4",
        "outputId": "b721b0fe-20b5-4b63-da0b-d5c9d81ebe17"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2:"
      ],
      "metadata": {
        "id": "d0WVCRgxnOFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.classify.util import accuracy as nltk_accuracy\n",
        "\n",
        "# Download the VADER lexicon\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Prepare data for sentiment analysis\n",
        "positive_reviews = [(movie_reviews.raw(fileid), 'positive') for fileid in movie_reviews.fileids('pos')]\n",
        "negative_reviews = [(movie_reviews.raw(fileid), 'negative') for fileid in movie_reviews.fileids('neg')]\n",
        "reviews = positive_reviews + negative_reviews\n",
        "\n",
        "# Shuffle the reviews for training and testing sets\n",
        "import random\n",
        "random.shuffle(reviews)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_set = reviews[:1600]\n",
        "test_set = reviews[1600:]\n",
        "\n",
        "# Create feature sets using BoW representation\n",
        "def extract_features(words):\n",
        "    return dict([(word, True) for word in words.split()])\n",
        "\n",
        "feature_sets = [(extract_features(words), sentiment) for (words, sentiment) in train_set]\n",
        "\n",
        "# Build the Naive Bayes classifier\n",
        "classifier = NaiveBayesClassifier.train(feature_sets)\n",
        "\n",
        "# Test the classifier on the testing set\n",
        "test_feature_sets = [(extract_features(words), sentiment) for (words, sentiment) in test_set]\n",
        "accuracy = nltk_accuracy(classifier, test_feature_sets)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7uFj5ckGYkg",
        "outputId": "bb1a2eb6-51a3-4f48-f209-8f60a8e63e71"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.69\n"
          ]
        }
      ]
    }
  ]
}