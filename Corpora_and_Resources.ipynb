{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#======================================================================\n",
        "#  Exercise:  1.Downloading and Accessing NLTK corpora\n",
        "#             2.Working with Text Corpora\n",
        "#             3.WordNet and its applications\n",
        "#             4.Using Lexical Resources\n",
        "#Author: Amruth Gadepalli\n",
        "#IIIT Banglore.2nd Year\n",
        "#\n",
        "#Date : 6th January 2024\n",
        "#======================================================================"
      ],
      "metadata": {
        "id": "dI7SHs3J-dx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2PY6S3pi-z2",
        "outputId": "d8d2c024-8581-469f-abf5-15f1477acf31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "txkIKmTelbcE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6rDszVWlgbm",
        "outputId": "03dcdc1a-3889-403a-e176-9f8fd1015df6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIEvDdqimK44",
        "outputId": "345baee1-b98a-4897-a6f2-e219d1642c1f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaVKd0AUlbHs",
        "outputId": "8a906449-4935-4bf7-b85c-c1886d292ea4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1"
      ],
      "metadata": {
        "id": "n_aHLpJjke-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1:"
      ],
      "metadata": {
        "id": "-m_8LloX_CNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Upgrade NLTK to the latest version\n",
        "!pip install --upgrade nltk\n",
        "\n",
        "# Download the NLTK data (if not already downloaded)\n",
        "nltk.download('gutenberg')\n",
        "\n",
        "# Import the Gutenberg corpus from NLTK\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "# Print the file IDs in the Gutenberg corpus\n",
        "print(gutenberg.fileids())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDHqCu2OoEMF",
        "outputId": "0783634d-5d3b-4365-f0fc-cdab7efd3410"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import gutenberg\n",
        "\n",
        "print(gutenberg.fileids())\n",
        "\n",
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlDiAf2oymvN",
        "outputId": "365864ee-73ee-4d6c-ae82-c00a8e67efaf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2:"
      ],
      "metadata": {
        "id": "HANbEfUVy6oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#A corpus is a large collection of data that is used to train the LLM.\n",
        "#Out of all the corpus in Gutenberg, we are going to take a file called austen-emma.txt\n",
        "#the variable emma is going to store all the words from this file\n",
        "emma =  gutenberg.words('austen-emma.txt')\n",
        "\n",
        "#the nummber of words in emma\n",
        "num_words=len(emma)\n",
        "\n",
        "#similiarly the number of lines in the file\n",
        "num_sentences=len(gutenberg.sents('austen-emma.txt'))\n",
        "\n",
        "avg_word_per_sentence=num_words/num_sentences\n",
        "\n",
        "print(\"number of words:\",num_words)\n",
        "print(\"number of sentences:\",num_sentences)\n",
        "print(\"average word per sentence:\",avg_word_per_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwb9yS1wy9sv",
        "outputId": "3a6fbcc0-63cb-4532-df57-2bf6458619a1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of words: 192427\n",
            "number of sentences: 7752\n",
            "average word per sentence: 24.822884416924666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 3:"
      ],
      "metadata": {
        "id": "KhQ_djVT3nOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#wordnet is a lexical database. A lexical database is a database that relates words based on their meanings.\n",
        "#the meaings can be related in many ways. For example,'happy' and 'joyful' are synonyms.\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "#the synonyms for the word 'Emperor'\n",
        "synonym_sets=wordnet.synsets('emperor')\n",
        "synonyms=[syn.lemmas()[0] for syn in synonym_sets]\n",
        "\n",
        "#let us get hypernym for the word 'lion'\n",
        "# example: flower(hypernym)-lotus(hyponym)\n",
        "\n",
        "synsets_lion=wordnet.synsets('lion')\n",
        "\n",
        "hypernyms=synsets_lion[0].hypernyms()\n",
        "\n",
        "print(\"synonyms of emperor\",synonyms)\n",
        "print(\"hypernyms of lion\",hypernyms)\n",
        "print(synsets_lion[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNQjFQ7l3oit",
        "outputId": "c89a09d1-f8c1-44b4-a7a6-d13c78029c29"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "synonyms of emperor [Lemma('emperor.n.01.emperor'), Lemma('emperor.n.02.emperor'), Lemma('emperor.n.03.emperor'), Lemma('emperor_butterfly.n.01.emperor_butterfly')]\n",
            "hypernyms of lion [Synset('big_cat.n.01')]\n",
            "Synset('lion.n.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 4:"
      ],
      "metadata": {
        "id": "Yvt3sbqk87G0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we can also find the various info about words such as meaning-\n",
        "definition = wordnet.synset('king.n.01').definition()\n",
        "\n",
        "#and examples to see how the word is used-\n",
        "examples = wordnet.synset('hero.n.01').examples()\n",
        "\n",
        "print(\"definition of king is:\",definition)\n",
        "print(\"examples of hero:\",examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iEYOyUc89LI",
        "outputId": "c5ce8c02-590a-4514-f332-bc3bbc6ceed5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "definition of king is: a male sovereign; ruler of a kingdom\n",
            "examples of king: ['RAF pilots were the heroes of the Battle of Britain']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v5bnDy9X1n7h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
